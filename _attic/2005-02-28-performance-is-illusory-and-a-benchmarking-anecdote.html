---
layout: post
title: "Performance is Illusory and a Benchmarking Anecdote"
permalink: performance-is-illusory-and-a-benchmarking-anecdote.html
---
<p><a href="http://www.almaer.com">Dion</a> has <a href="http://www.almaer.com/blog/archives/000767.html">called</a> for a little restraint on performance comparisons between <a href="http://www.rubyonrails.org/">Rails</a> and <a href="http://java.sun.com/j2ee/">J2EE</a>.  I don't have any special place in my heart for either one, but restraint is certainly warranted, as there are <a href="http://www.quotegarden.com/statistics.html">four kinds</a> of lies -- lies, damn lies, statstics, and benchmarks...  A thorough and careful design, not any particular language and certainly not any particular framework, is the shortest path to elegance.  (IMHO.)</p>

<p>On this subject, one <a href="http://acmqueue.com/modules.php?name=Content&amp;pa=showpage&amp;pid=239">study</a> concluded that the most significant overall risk factor in a project is not using a <em>particular</em> methodology but rather using the <em>wrong</em> one.  Knowing the right one requires luck, an experienced mentor, or proximity to a sufficient number of acknowledged, dissected <a href="http://blogs.pragprog.com/cgi-bin/pragdave.cgi/Random/Mistakes.rdoc">failures</a>.</p>

<p>Like most things, this brings to mind an anecdote, and this one is even relevant.  Once upon a time (ages ago -- 2001), we needed to meet a performance benchmark (10<sup>x</sup> end-to-end transactions per eight hours) for a customer before we closed a license agreement.  (They paid for the proof of concept and benchmark on their hardware, which is the fair thing to do.)  We configured a dual-CPU test system on a cheap beater box with a fibre channel array built from pieces that we bought off <a href="http://www.ebay.com">eBay</a>, some random FC cabling provider, and a liquidator who specialized in cheap FC drives.  The total cost was something like $700.  We used an empty PC case to hold the array with a paperclip to short the on/off jumper for the power supply.  We sat down with a profiler (the final source of Truth when performance tuning) and tuned things to beat the required performance benchmark by a factor of two on our FrankenPC.  Feeling good, we set everything up on a couple of the customer's <a href="http://www.hoise.com/primeur/01/articles/monthly/AE-PR-03-01-1.html">HP N-class</a> servers, and...  the system fell short of the benchmark <em>by a factor of three</em>, i.e., it underperformed the gimpy PC <em>by a factor of six</em>.</p>

<p>So, what gives?  Why would a couple of $70,000 server-class machines with a staff of trained professionals to take care of them be slower than a $700 FrankenPC?  After a good number of possible causes were eliminated, it turned out that the disk array for the SAN that supported the two servers was configured in the <em>worst</em> possible way, and after that was corrected, the system sailed past the required performance mark as expected.</p>
